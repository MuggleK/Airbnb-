{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings,time\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('train_removed_all.csv')\n",
    "Ytrain = pd.read_csv('Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213451, 349)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>tfa_year</th>\n",
       "      <th>tfa_month</th>\n",
       "      <th>tfa_day</th>\n",
       "      <th>tfa_weekday_1</th>\n",
       "      <th>tfa_weekday_2</th>\n",
       "      <th>tfa_weekday_4</th>\n",
       "      <th>tfa_weekday_5</th>\n",
       "      <th>tfa_weekday_6</th>\n",
       "      <th>tfa_weekday_7</th>\n",
       "      <th>...</th>\n",
       "      <th>act_std_</th>\n",
       "      <th>act_mean_</th>\n",
       "      <th>act_type_len_</th>\n",
       "      <th>act_type_std_</th>\n",
       "      <th>act_type_mean_</th>\n",
       "      <th>act_detail_std_</th>\n",
       "      <th>act_detail_mean_</th>\n",
       "      <th>dev_type_len_</th>\n",
       "      <th>dev_type_std_</th>\n",
       "      <th>dev_type_mean_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  tfa_year  tfa_month  tfa_day  tfa_weekday_1  tfa_weekday_2  \\\n",
       "0  100      2009          3       19              0              0   \n",
       "1   35      2009          5       23              0              0   \n",
       "2   55      2009          6        9              0              1   \n",
       "3   35      2009         10       31              0              0   \n",
       "4   35      2009         12        8              0              1   \n",
       "\n",
       "   tfa_weekday_4  tfa_weekday_5  tfa_weekday_6  tfa_weekday_7  ...  act_std_  \\\n",
       "0              1              0              0              0  ...      -2.0   \n",
       "1              0              0              1              0  ...      -2.0   \n",
       "2              0              0              0              0  ...      -2.0   \n",
       "3              0              0              1              0  ...      -2.0   \n",
       "4              0              0              0              0  ...      -2.0   \n",
       "\n",
       "   act_mean_  act_type_len_  act_type_std_  act_type_mean_  act_detail_std_  \\\n",
       "0       -2.0           -2.0           -2.0            -2.0             -2.0   \n",
       "1       -2.0           -2.0           -2.0            -2.0             -2.0   \n",
       "2       -2.0           -2.0           -2.0            -2.0             -2.0   \n",
       "3       -2.0           -2.0           -2.0            -2.0             -2.0   \n",
       "4       -2.0           -2.0           -2.0            -2.0             -2.0   \n",
       "\n",
       "   act_detail_mean_  dev_type_len_  dev_type_std_  dev_type_mean_  \n",
       "0              -2.0           -2.0           -2.0            -2.0  \n",
       "1              -2.0           -2.0           -2.0            -2.0  \n",
       "2              -2.0           -2.0           -2.0            -2.0  \n",
       "3              -2.0           -2.0           -2.0            -2.0  \n",
       "4              -2.0           -2.0           -2.0            -2.0  \n",
       "\n",
       "[5 rows x 349 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X.columns\n",
    "X.drop(['Unnamed: 0'],axis = 1,inplace = True)\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213451, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type\n",
       "0    NDF\n",
       "1    NDF\n",
       "2     US\n",
       "3  other\n",
       "4     US"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.drop(['Unnamed: 0'],axis = 1,inplace = True)\n",
    "print(Ytrain.shape)\n",
    "Ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42690, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53660</th>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128455</th>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102555</th>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79215</th>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160417</th>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type\n",
       "53660      US\n",
       "128455    NDF\n",
       "102555    NDF\n",
       "79215     NDF\n",
       "160417  other"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按1/5比例拆分数据\n",
    "xtrain = X.sample(frac = 1/5,axis = 0)\n",
    "y_dict = {}\n",
    "for i in xtrain.index:\n",
    "    y_dict[i] = Ytrain.iloc[i].values[0]\n",
    "\n",
    "df_y = pd.DataFrame(pd.Series(y_dict),columns=['type'])  # dict -> Series -> DataFrame\n",
    "print(df_y.shape)\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 此函数用于把源数据集按1/k的比例分为5个子集\n",
    "def spilt(x,y,k = 5,n = 5):\n",
    "    Xtrain_list = []\n",
    "    Ytrain_list = []\n",
    "    for i in range(n):\n",
    "        df_x = X.sample(frac = 1/k,axis = 0)\n",
    "        y_dict = {}\n",
    "        for i in df_x.index:\n",
    "            y_dict[i] = Ytrain.iloc[i].values[0]\n",
    "\n",
    "        df_y = pd.DataFrame(pd.Series(y_dict),columns=['type'])  # dict -> Series -> DataFrame\n",
    "        # 标准化 X\n",
    "        transfer_std = StandardScaler()\n",
    "        Xtrain = transfer_std.fit_transform(df_x)\n",
    "        # 编码 Y\n",
    "        l_e = LabelEncoder()\n",
    "        encode_label = l_e.fit_transform(df_y.values)\n",
    "\n",
    "        Xtrain_list.append(Xtrain)\n",
    "        Ytrain_list.append(encode_label)\n",
    "    return Xtrain_list,Ytrain_list\n",
    "    \n",
    "# 拆分数据集可使用 留出法 + cross_val_score交叉验证直接拆分 -> 直接求得K折的平均值\n",
    "# KFold交叉验证拆分（可观察过程）-> 先将原始数据集划分，再求K折的每个准确率再求平均\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train,x_test,y_train,y_test = train_test_split(Xtrain,Y,test_size = 0.25,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_list,Ytrain_list = spilt(X,Ytrain,k = 7,n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 7,  7,  8, ...,  7, 10,  7]),\n",
       " array([ 7,  7, 10, ...,  7,  7, 10]),\n",
       " array([ 3,  0,  7, ...,  7, 10,  7]),\n",
       " array([ 7, 10,  7, ..., 10,  7,  7]),\n",
       " array([11,  1,  7, ...,  4,  7,  7]),\n",
       " array([10, 10,  7, ...,  7,  7,  5]),\n",
       " array([10,  7, 10, ...,  7, 10,  7])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    y_true : array, shape = [n_samples] #数据\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array, shape = [n_samples, n_classes] #预测的分数\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1] #分数从高到低排序\n",
    "    y_true = np.take(y_true, order[:k]) #取出前k[0,k）个分数\n",
    "      \n",
    "    gain = 2 ** y_true - 1   \n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "  \n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):   \n",
    "\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_truth : array, shape = [n_samples]\n",
    "        Ground truth (true labels represended as integers).\n",
    "    predictions : array, shape = [n_samples, n_classes] \n",
    "        Predicted probabilities. 预测的概率\n",
    "    k : int\n",
    "        Rank.\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(len(predictions) + 1))\n",
    "    T = lb.transform(ground_truth)    \n",
    "    scores = []\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predictions):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT训练集NDCG为0.8088806175964844s\n",
      "DT测试集NDCG为0.8085779063433396s\n",
      "DT共耗时1027s\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import hamming_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "start = time.time()\n",
    "# # 网格搜索 + 交叉验证\n",
    "# DT_estimator = DecisionTreeClassifier(min_samples_leaf = 12) # class_weight='balanced'  min_samples_leaf = 12\n",
    "# dt_param_dict = {'max_depth':range(10,101,10),'max_leaf_nodes':range(2,11,2)} # min_samples_leaf是最小分类数，全部数据集时需要指定12类别  'max_leaf_nodes':range(2,11,2)\n",
    "# dt_estimator = GridSearchCV(DT_estimator,param_grid = dt_param_dict,cv = 5)\n",
    "# dt_estimator.fit(x_train,y_train)\n",
    "# dt_y_predict = dt_estimator.predict(x_test)\n",
    "\n",
    "# dt_report = classification_report(dt_y_predict,y_test,digits=5) # 准确率 + f1...\n",
    "# dt_hamming_distance = hamming_loss(y_test,dt_y_predict) # 海明距离（多分类评估指标之一）\n",
    "# dt_hamming_distance_train  = hamming_loss(dt_estimator.predict(x_train),y_train)  # 训练集海明距离\n",
    "# dt_acc_score = dt_estimator.score(x_test,y_test)  # 测试集准确率\n",
    "# print(dt_estimator.best_params_)\n",
    "# print(dt_report)\n",
    "# print('--'*50)\n",
    "# print('训练集海明距离为{}'.format(dt_hamming_distance_train))\n",
    "# print('测试集海明距离为{}'.format(dt_hamming_distance))\n",
    "# print('测试集准确率为{}'.format(dt_acc_score))\n",
    "# print('--'*50)\n",
    "\n",
    "## 直接训练，得出ndcg_score\n",
    "dt_ndcg_estimator = DecisionTreeClassifier(min_samples_leaf = 12,max_depth = 10,max_leaf_nodes = 9)\n",
    "dt_kf = KFold(n_splits=5,random_state = 100)\n",
    "\n",
    "dt_train_score_final = []\n",
    "dt_test_score_final = []\n",
    "for i in range(5):\n",
    "    dt_ndcg_train_score_list = []\n",
    "    dt_ndcg_test_score_list = []\n",
    "    for train_index,test_index in dt_kf.split(Xtrain_list[i],Ytrain_list[i]):\n",
    "    #     print(train_index,test_index)\n",
    "        X_train,X_test = Xtrain_list[i][train_index,:],Xtrain_list[i][test_index,:]\n",
    "        Y_train,Y_test = Ytrain_list[i][train_index],Ytrain_list[i][test_index]\n",
    "\n",
    "        dt_ndcg_estimator.fit(X_train,Y_train)\n",
    "\n",
    "        dt_ndcg_train_proba = dt_ndcg_estimator.predict_proba(X_train)\n",
    "        dt_ndcg_test_proba = dt_ndcg_estimator.predict_proba(X_test)\n",
    "\n",
    "        dt_ndcg_train_score = ndcg_score(Y_train,dt_ndcg_train_proba,k = 3) # 训练集ndcg\n",
    "        dt_ndcg_test_score = ndcg_score(Y_test,dt_ndcg_test_proba,k = 3) # 测试集ndcg\n",
    "\n",
    "        dt_ndcg_train_score_list.append(dt_ndcg_train_score)\n",
    "        dt_ndcg_test_score_list.append(dt_ndcg_test_score)\n",
    "\n",
    "    dt_train_score_final.append(np.mean(dt_ndcg_train_score_list))\n",
    "    dt_test_score_final.append(np.mean(dt_ndcg_test_score_list))\n",
    "\n",
    "end = time.time()\n",
    "print('DT训练集NDCG为{}s'.format(np.mean(dt_train_score_final)))\n",
    "print('DT测试集NDCG为{}s'.format(np.mean(dt_test_score_final)))\n",
    "print('DT共耗时{}s'.format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf算法耗时53501s\n",
      "SVM-poly算法耗时48070s\n",
      "SVM-linear算法耗时40195s\n",
      "训练集分数为{'SVM-rbf': 0.8107632623534101, 'SVM-poly': 0.8093641861523704, 'SVM-linear': 0.8069913439305136}\n",
      "测试集分数为{'SVM-rbf': 0.8068063087191353, 'SVM-poly': 0.806847143367375, 'SVM-linear': 0.8065592941589017}\n"
     ]
    }
   ],
   "source": [
    "# 根据不同核函数的SVM\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "TOL = 1e-4\n",
    "MAX_ITER = 1000\n",
    "RANDOM_STATE = 100\n",
    "\n",
    "svm_list = {\n",
    "    \n",
    "    'SVM-rbf': SVC(kernel='rbf',\n",
    "                   max_iter=MAX_ITER,\n",
    "                   tol=TOL, random_state=RANDOM_STATE,\n",
    "                   decision_function_shape='ovr',probability=True),     \n",
    "    \n",
    "    'SVM-poly': SVC(kernel='poly',\n",
    "                   max_iter=MAX_ITER,\n",
    "                   tol=TOL, random_state=RANDOM_STATE,\n",
    "                       decision_function_shape='ovr',probability=True),     \n",
    "    \n",
    "    'SVM-linear': SVC(kernel='linear',\n",
    "                      max_iter=MAX_ITER,\n",
    "                      tol=TOL, \n",
    "                      random_state=RANDOM_STATE,\n",
    "                      decision_function_shape='ovr',probability=True),  \n",
    "    \n",
    "#     'LinearSVC': LinearSVC(max_iter=MAX_ITER,\n",
    "#                             tol=TOL,\n",
    "#                             random_state=RANDOM_STATE,\n",
    "#                             multi_class = 'ovr')  \n",
    "                            \n",
    "}\n",
    "svm_kf = KFold(n_splits=5,random_state = 100)\n",
    "svm_train_ndcg_score_list = {}\n",
    "svm_test_ndcg_score_list = {}\n",
    "for key,value in svm_list.items():\n",
    "    svm_estimator = value\n",
    "    svm_train_score_final = []\n",
    "    svm_test_score_final = []\n",
    "    start = time.time()\n",
    "    for i in range(5):\n",
    "        svm_score_train_iter = []\n",
    "        svm_score_test_iter = []\n",
    "#         start = time.time()\n",
    "        for train_index,test_index in svm_kf.split(Xtrain_list[i],Ytrain_list[i]):\n",
    "    #     print(train_index,test_index)\n",
    "            X_train,X_test = Xtrain_list[i][train_index,:],Xtrain_list[i][test_index,:]\n",
    "            Y_train,Y_test = Ytrain_list[i][train_index],Ytrain_list[i][test_index]\n",
    "\n",
    "            svm_estimator.fit(X_train,Y_train)\n",
    "\n",
    "            svm_train_ndcg_score = ndcg_score(Y_train,svm_estimator.predict_proba(X_train),k = 5)  #训练集ndcg\n",
    "            svm_test_ndcg_score = ndcg_score(Y_test,svm_estimator.predict_proba(X_test),k = 5)  #测试集ndcg\n",
    "\n",
    "            svm_score_train_iter.append(svm_train_ndcg_score)\n",
    "            svm_score_test_iter.append(svm_test_ndcg_score)\n",
    "        svm_train_score_final.append(np.mean(svm_score_train_iter))\n",
    "        svm_test_score_final.append(np.mean(svm_score_test_iter))\n",
    "    \n",
    "    for i in range(len(svm_score_train_iter)):\n",
    "        svm_train_ndcg_score_list[key] = np.mean(svm_train_score_final[i])\n",
    "    for j in range(len(svm_score_test_iter)):\n",
    "        svm_test_ndcg_score_list[key] = np.mean(svm_test_score_final[i])\n",
    "    end = time.time()\n",
    "    print('{}算法耗时{}s'.format(key,int(end-start)))\n",
    "# print(svm_score_dict)\n",
    "print('训练集分数为{}'.format(svm_train_ndcg_score_list))\n",
    "print('测试集分数为{}'.format(svm_test_ndcg_score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集NDCG为0.825012892629808\n",
      "测试集NDCG为0.825012892629808\n",
      "LR共耗时48313s\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings,time\n",
    "from sklearn.model_selection import KFold\n",
    "svm_kf = KFold(n_splits=5,random_state = 100)\n",
    "iters=[300,500,700,1000]\n",
    "start = time.time()\n",
    "lr_train_score_final = []\n",
    "lr_test_score_final = []\n",
    "for i in range(5):\n",
    "    lr_train_ndcg_score_list = []\n",
    "    lr_test_ndcg_score_list = []\n",
    "    for index,value in enumerate(iters):\n",
    "        lr_estimator = LogisticRegression(C=1.0,max_iter=value, tol=1e-5, solver='newton-cg', multi_class='multinomial',random_state = 100, n_jobs = -1) # 大数据solver='newton-cg'\n",
    "        lr_score_train_iter = []\n",
    "        lr_score_test_iter = []\n",
    "        for train_index,test_index in svm_kf.split(Xtrain_list[i],Ytrain_list[i]):\n",
    "    #     print(train_index,test_index)\n",
    "            X_train,X_test = Xtrain_list[i][train_index,:],Xtrain_list[i][test_index,:]\n",
    "            Y_train,Y_test = Ytrain_list[i][train_index],Ytrain_list[i][test_index]\n",
    "\n",
    "            lr_estimator.fit(X_train,Y_train)\n",
    "\n",
    "            lr_train_ndcg_score = ndcg_score(Y_train,lr_estimator.predict_proba(X_train),k = 5)  #训练集ndcg\n",
    "            lr_test_ndcg_score = ndcg_score(Y_test,lr_estimator.predict_proba(X_test),k = 5)  #测试集ndcg\n",
    "\n",
    "            lr_score_train_iter.append(lr_train_ndcg_score) #算出每一折的值\n",
    "            lr_score_test_iter.append(lr_test_ndcg_score)\n",
    "        lr_train_ndcg_score_list.append(np.mean(lr_score_train_iter)) #算出每一个iter中交叉验证的平均值\n",
    "        lr_test_ndcg_score_list.append(np.mean(lr_score_test_iter))\n",
    "        \n",
    "    lr_test_score_final.append(np.mean(lr_train_ndcg_score_list))\n",
    "    lr_test_score_final.append(np.mean(lr_test_ndcg_score_list))\n",
    "end = time.time()\n",
    "print('训练集NDCG为{}'.format(np.mean(lr_train_score_final)))\n",
    "print('测试集NDCG为{}'.format(np.mean(lr_test_score_final)))\n",
    "print('LR共耗时{}s'.format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF算法耗时255s\n",
      "AdaBoost算法耗时475s\n",
      "Bagging算法耗时2187s\n",
      "ExtraTree算法耗时267s\n",
      "GraBoost算法耗时23726s\n",
      "训练集分数为{'RF': 0.8255420441904817, 'AdaBoost': 0.8040145522393344, 'Bagging': 0.9953975722887847, 'ExtraTree': 0.8187004672345214, 'GraBoost': 0.9493455091377362}\n",
      "测试集分数为{'RF': 0.8093385432841202, 'AdaBoost': 0.8035797764349348, 'Bagging': 0.8049099222978253, 'ExtraTree': 0.8056483837874673, 'GraBoost': 0.810463947869908}\n"
     ]
    }
   ],
   "source": [
    "# RF,AdaBoost，GradientBoost，Bagging\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "LEARNING_RATE = 0.1\n",
    "N_ESTIMATORS = 100\n",
    "RANDOM_STATE = 100\n",
    "MAX_DEPTH = 9\n",
    "tree_kf = KFold(n_splits=5,random_state = 100)\n",
    "#建了一个tree字典\n",
    "tree_list ={\n",
    "    'RF': RandomForestClassifier(n_estimators=N_ESTIMATORS,\n",
    "                                 max_depth=MAX_DEPTH,\n",
    "                                 random_state=RANDOM_STATE),\n",
    "    \n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=N_ESTIMATORS,\n",
    "                                   learning_rate=LEARNING_RATE,\n",
    "                                   random_state=RANDOM_STATE),\n",
    "    \n",
    "    'Bagging': BaggingClassifier(n_estimators=N_ESTIMATORS,\n",
    "                                 random_state=RANDOM_STATE),\n",
    "    \n",
    "    'ExtraTree': ExtraTreesClassifier(max_depth=MAX_DEPTH,\n",
    "                                      n_estimators=N_ESTIMATORS,\n",
    "                                      random_state=RANDOM_STATE),\n",
    "    \n",
    "    'GraBoost': GradientBoostingClassifier(learning_rate=LEARNING_RATE,\n",
    "                                           max_depth=MAX_DEPTH,\n",
    "                                           n_estimators=N_ESTIMATORS,\n",
    "                                           random_state=RANDOM_STATE)\n",
    "}\n",
    "tree_train_ndcg_score_list = {}\n",
    "tree_test_ndcg_score_list = {}\n",
    "for key,value in tree_list.items():\n",
    "    tree_estimator = value\n",
    "    \n",
    "    tree_train_score_final = []\n",
    "    tree_test_score_final = []\n",
    "    for i in range(5):\n",
    "        tree_score_train_iter = []\n",
    "        tree_score_test_iter = []\n",
    "        start = time.time()\n",
    "        for train_index,test_index in tree_kf.split(Xtrain_list[i],Ytrain_list[i]):\n",
    "    #     print(train_index,test_index)\n",
    "            X_train,X_test = Xtrain_list[i][train_index,:],Xtrain_list[i][test_index,:]\n",
    "            Y_train,Y_test = Ytrain_list[i][train_index],Ytrain_list[i][test_index]\n",
    "\n",
    "            tree_estimator.fit(X_train,Y_train)\n",
    "#             print(X_train.shape)\n",
    "#             print(Y_train.shape)\n",
    "            tree_train_ndcg_score = ndcg_score(Y_train,tree_estimator.predict_proba(X_train),k = 5)  #训练集ndcg\n",
    "            tree_test_ndcg_score = ndcg_score(Y_test,tree_estimator.predict_proba(X_test),k = 5)  #测试集ndcg\n",
    "\n",
    "            tree_score_train_iter.append(tree_train_ndcg_score)\n",
    "            tree_score_test_iter.append(tree_test_ndcg_score)\n",
    "            \n",
    "        tree_train_score_final.append(np.mean(tree_score_train_iter))\n",
    "        tree_test_score_final.append(np.mean(tree_score_test_iter))\n",
    "    for i in range(len(tree_score_train_iter)):\n",
    "        tree_train_ndcg_score_list[key] = np.mean(tree_train_score_final[i])\n",
    "    for j in range(len(tree_score_test_iter)):\n",
    "        tree_test_ndcg_score_list[key] = np.mean(tree_test_score_final[i])\n",
    "    end = time.time()\n",
    "    print('{}算法耗时{}s'.format(key,int(end-start)))\n",
    "print('训练集分数为{}'.format(tree_train_ndcg_score_list))\n",
    "print('测试集分数为{}'.format(tree_test_ndcg_score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集分数为{'RF': 0.8309136097047173, 'AdaBoost': 0.8393518268629461, 'Bagging': 0.9591210072671774, 'ExtraTree': 0.8287156479371033, 'GraBoost': 0.9389081113987616}\n",
      "测试集分数为{'RF': 0.8366363503737687, 'AdaBoost': 0.8512367478668409, 'Bagging': 0.8303176891925171, 'ExtraTree': 0.8369002700153513, 'GraBoost': 0.8285280799796116}\n"
     ]
    }
   ],
   "source": [
    "print('训练集分数为{}'.format(tree_train_ndcg_score_list))\n",
    "print('测试集分数为{}'.format(tree_test_ndcg_score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.364434\ttest-merror:0.367273\ttrain-ndcg5:0.827848\ttest-ndcg5:0.820532\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.352628\ttest-merror:0.36301\ttrain-ndcg5:0.835724\ttest-ndcg5:0.824556\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.364434\ttest-merror:0.367273\ttrain-ndcg5:0.827848\ttest-ndcg5:0.820532\n",
      "\n",
      "[0]\ttrain-merror:0.363204\ttest-merror:0.378423\ttrain-ndcg5:0.827393\ttest-ndcg5:0.818079\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.352546\ttest-merror:0.372356\ttrain-ndcg5:0.835046\ttest-ndcg5:0.822141\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.363204\ttest-merror:0.378423\ttrain-ndcg5:0.827393\ttest-ndcg5:0.818079\n",
      "\n",
      "[0]\ttrain-merror:0.366812\ttest-merror:0.361207\ttrain-ndcg5:0.82742\ttest-ndcg5:0.823166\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.356604\ttest-merror:0.3576\ttrain-ndcg5:0.834813\ttest-ndcg5:0.825516\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.366812\ttest-merror:0.361207\ttrain-ndcg5:0.82742\ttest-ndcg5:0.823166\n",
      "\n",
      "[0]\ttrain-merror:0.392744\ttest-merror:0.423582\ttrain-ndcg5:0.816692\ttest-ndcg5:0.801896\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.354089\ttest-merror:0.38324\ttrain-ndcg5:0.835073\ttest-ndcg5:0.817531\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.392744\ttest-merror:0.423582\ttrain-ndcg5:0.816692\ttest-ndcg5:0.801896\n",
      "\n",
      "[0]\ttrain-merror:0.394753\ttest-merror:0.400131\ttrain-ndcg5:0.814995\ttest-ndcg5:0.812946\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.356139\ttest-merror:0.377009\ttrain-ndcg5:0.83335\ttest-ndcg5:0.823236\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.394753\ttest-merror:0.400131\ttrain-ndcg5:0.814995\ttest-ndcg5:0.812946\n",
      "\n",
      "[0]\ttrain-merror:0.362671\ttest-merror:0.376291\ttrain-ndcg5:0.828437\ttest-ndcg5:0.817772\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.350988\ttest-merror:0.372848\ttrain-ndcg5:0.835427\ttest-ndcg5:0.82015\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.362671\ttest-merror:0.376291\ttrain-ndcg5:0.828437\ttest-ndcg5:0.817772\n",
      "\n",
      "[0]\ttrain-merror:0.365787\ttest-merror:0.365142\ttrain-ndcg5:0.826051\ttest-ndcg5:0.825506\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.355087\ttest-merror:0.362354\ttrain-ndcg5:0.833037\ttest-ndcg5:0.827697\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.365787\ttest-merror:0.365142\ttrain-ndcg5:0.826051\ttest-ndcg5:0.825506\n",
      "\n",
      "[0]\ttrain-merror:0.36181\ttest-merror:0.375635\ttrain-ndcg5:0.827855\ttest-ndcg5:0.818277\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.350578\ttest-merror:0.369733\ttrain-ndcg5:0.835872\ttest-ndcg5:0.820724\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.36181\ttest-merror:0.375635\ttrain-ndcg5:0.827855\ttest-ndcg5:0.818277\n",
      "\n",
      "[0]\ttrain-merror:0.394138\ttest-merror:0.407019\ttrain-ndcg5:0.8165\ttest-ndcg5:0.807868\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.356344\ttest-merror:0.374057\ttrain-ndcg5:0.832991\ttest-ndcg5:0.821619\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.394138\ttest-merror:0.407019\ttrain-ndcg5:0.8165\ttest-ndcg5:0.807868\n",
      "\n",
      "[0]\ttrain-merror:0.396352\ttest-merror:0.401115\ttrain-ndcg5:0.815256\ttest-ndcg5:0.808327\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.355114\ttest-merror:0.36717\ttrain-ndcg5:0.833905\ttest-ndcg5:0.823148\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.396352\ttest-merror:0.401115\ttrain-ndcg5:0.815256\ttest-ndcg5:0.808327\n",
      "\n",
      "[0]\ttrain-merror:0.365869\ttest-merror:0.376947\ttrain-ndcg5:0.825891\ttest-ndcg5:0.818598\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.354185\ttest-merror:0.368749\ttrain-ndcg5:0.834222\ttest-ndcg5:0.822675\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.365869\ttest-merror:0.376947\ttrain-ndcg5:0.825891\ttest-ndcg5:0.818598\n",
      "\n",
      "[0]\ttrain-merror:0.367016\ttest-merror:0.378751\ttrain-ndcg5:0.825876\ttest-ndcg5:0.8174\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.351316\ttest-merror:0.374816\ttrain-ndcg5:0.834846\ttest-ndcg5:0.820104\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.367016\ttest-merror:0.378751\ttrain-ndcg5:0.825876\ttest-ndcg5:0.8174\n",
      "\n",
      "[0]\ttrain-merror:0.368451\ttest-merror:0.361371\ttrain-ndcg5:0.824799\ttest-ndcg5:0.825797\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.353776\ttest-merror:0.358583\ttrain-ndcg5:0.833309\ttest-ndcg5:0.828372\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.368451\ttest-merror:0.361371\ttrain-ndcg5:0.824799\ttest-ndcg5:0.825797\n",
      "\n",
      "[0]\ttrain-merror:0.394261\ttest-merror:0.401115\ttrain-ndcg5:0.816314\ttest-ndcg5:0.808722\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.359541\ttest-merror:0.372253\ttrain-ndcg5:0.832225\ttest-ndcg5:0.819754\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.394261\ttest-merror:0.401115\ttrain-ndcg5:0.816314\ttest-ndcg5:0.808722\n",
      "\n",
      "[0]\ttrain-merror:0.394835\ttest-merror:0.41489\ttrain-ndcg5:0.816345\ttest-ndcg5:0.803757\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.356098\ttest-merror:0.3857\ttrain-ndcg5:0.833939\ttest-ndcg5:0.815248\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.394835\ttest-merror:0.41489\ttrain-ndcg5:0.816345\ttest-ndcg5:0.803757\n",
      "\n",
      "[0]\ttrain-merror:0.360171\ttest-merror:0.372684\ttrain-ndcg5:0.829574\ttest-ndcg5:0.822602\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.351562\ttest-merror:0.368585\ttrain-ndcg5:0.836473\ttest-ndcg5:0.824598\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.360171\ttest-merror:0.372684\ttrain-ndcg5:0.829574\ttest-ndcg5:0.822602\n",
      "\n",
      "[0]\ttrain-merror:0.3589\ttest-merror:0.373504\ttrain-ndcg5:0.830705\ttest-ndcg5:0.822139\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.348487\ttest-merror:0.372192\ttrain-ndcg5:0.837254\ttest-ndcg5:0.82255\n",
      "[6]\ttrain-merror:0.341313\ttest-merror:0.369405\ttrain-ndcg5:0.841935\ttest-ndcg5:0.823448\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-merror:0.354595\ttest-merror:0.373996\ttrain-ndcg5:0.833547\ttest-ndcg5:0.822091\n",
      "\n",
      "[0]\ttrain-merror:0.362958\ttest-merror:0.370061\ttrain-ndcg5:0.829144\ttest-ndcg5:0.821742\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.349963\ttest-merror:0.36465\ttrain-ndcg5:0.83701\ttest-ndcg5:0.825325\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.362958\ttest-merror:0.370061\ttrain-ndcg5:0.829144\ttest-ndcg5:0.821742\n",
      "\n",
      "[0]\ttrain-merror:0.396393\ttest-merror:0.395867\ttrain-ndcg5:0.816656\ttest-ndcg5:0.812312\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.35454\ttest-merror:0.368317\ttrain-ndcg5:0.835786\ttest-ndcg5:0.823954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.396393\ttest-merror:0.395867\ttrain-ndcg5:0.816656\ttest-ndcg5:0.812312\n",
      "\n",
      "[0]\ttrain-merror:0.390736\ttest-merror:0.408167\ttrain-ndcg5:0.818517\ttest-ndcg5:0.807275\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.356385\ttest-merror:0.372581\ttrain-ndcg5:0.835308\ttest-ndcg5:0.821435\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.390736\ttest-merror:0.408167\ttrain-ndcg5:0.818517\ttest-ndcg5:0.807275\n",
      "\n",
      "[0]\ttrain-merror:0.368328\ttest-merror:0.37334\ttrain-ndcg5:0.825098\ttest-ndcg5:0.819853\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.357711\ttest-merror:0.366617\ttrain-ndcg5:0.831603\ttest-ndcg5:0.82498\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.368328\ttest-merror:0.37334\ttrain-ndcg5:0.825098\ttest-ndcg5:0.819853\n",
      "\n",
      "[0]\ttrain-merror:0.368615\ttest-merror:0.37088\ttrain-ndcg5:0.824862\ttest-ndcg5:0.819115\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.356153\ttest-merror:0.364978\ttrain-ndcg5:0.833116\ttest-ndcg5:0.821874\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.368615\ttest-merror:0.37088\ttrain-ndcg5:0.824862\ttest-ndcg5:0.819115\n",
      "\n",
      "[0]\ttrain-merror:0.367098\ttest-merror:0.375471\ttrain-ndcg5:0.825712\ttest-ndcg5:0.820251\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.35398\ttest-merror:0.3717\ttrain-ndcg5:0.83374\ttest-ndcg5:0.822055\n",
      "[6]\ttrain-merror:0.34734\ttest-merror:0.371372\ttrain-ndcg5:0.837846\ttest-ndcg5:0.822436\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-merror:0.362589\ttest-merror:0.376455\ttrain-ndcg5:0.828605\ttest-ndcg5:0.820162\n",
      "\n",
      "[0]\ttrain-merror:0.397131\ttest-merror:0.418498\ttrain-ndcg5:0.814192\ttest-ndcg5:0.800063\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.357327\ttest-merror:0.386192\ttrain-ndcg5:0.832606\ttest-ndcg5:0.813055\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.397131\ttest-merror:0.418498\ttrain-ndcg5:0.814192\ttest-ndcg5:0.800063\n",
      "\n",
      "[0]\ttrain-merror:0.401845\ttest-merror:0.402427\ttrain-ndcg5:0.811713\ttest-ndcg5:0.809068\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.359582\ttest-merror:0.368153\ttrain-ndcg5:0.830942\ttest-ndcg5:0.823305\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.401845\ttest-merror:0.402427\ttrain-ndcg5:0.811713\ttest-ndcg5:0.809068\n",
      "\n",
      "\n",
      "The training score is: 0.8376664179552055\n",
      "The cv score is: 0.8227667390448075\n",
      "\n",
      "原生xgboost共耗时1669s\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def customized_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    top = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        top.append(np.argsort(preds[i])[::-1][:5])\n",
    "    mat = np.reshape(np.repeat(labels,np.shape(top)[1]) == np.array(top).ravel(),np.array(top).shape).astype(int)\n",
    "    score = np.mean(np.sum(mat/np.log2(np.arange(2, mat.shape[1] + 2)),axis = 1))\n",
    "    return 'ndcg5', score\n",
    "# xgboost parameters\n",
    "\n",
    "NUM_XGB = 200\n",
    "RANDOM_STATE = 100\n",
    "\n",
    "params = {}\n",
    "params['colsample_bytree'] = 0.6\n",
    "params['max_depth'] = 6\n",
    "params['subsample'] = 0.8\n",
    "params['eta'] = 0.3\n",
    "params['seed'] = RANDOM_STATE\n",
    "params['num_class'] = 12\n",
    "params['objective'] = 'multi:softprob'   # output the probability instead of class. \n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state=RANDOM_STATE)\n",
    "\n",
    "k_ndcg = 5\n",
    "train_score_final = []\n",
    "cv_score_final = []\n",
    "for i in range(5):\n",
    "    train_score_iter = []\n",
    "    cv_score_iter = []\n",
    "    for train_index, test_index in kf.split(Xtrain_list[i], Ytrain_list[i]):\n",
    "\n",
    "        X_train, X_test = Xtrain_list[i][train_index, :], Xtrain_list[i][test_index, :]\n",
    "        y_train, y_test = Ytrain_list[i][train_index], Ytrain_list[i][test_index]\n",
    "\n",
    "        train_xgb = xgb.DMatrix(X_train, label= y_train)\n",
    "        test_xgb = xgb.DMatrix(X_test, label = y_test)\n",
    "\n",
    "        watchlist = [ (train_xgb,'train'), (test_xgb, 'test') ]\n",
    "\n",
    "        bst = xgb.train(params, \n",
    "                         train_xgb,\n",
    "                         NUM_XGB,\n",
    "                         watchlist,\n",
    "                         feval = customized_eval,\n",
    "                         verbose_eval = 3,\n",
    "                         early_stopping_rounds = 5)\n",
    "\n",
    "\n",
    "        #bst = xgb.train( params, dtrain, num_round, evallist )\n",
    "\n",
    "        y_pred = np.array(bst.predict(test_xgb))\n",
    "        y_pred_train = np.array(bst.predict(train_xgb))\n",
    "        train_ndcg_score = ndcg_score(y_train, y_pred_train , k = k_ndcg)\n",
    "        cv_ndcg_score = ndcg_score(y_test, y_pred, k=k_ndcg)\n",
    "\n",
    "        train_score_iter.append(train_ndcg_score)\n",
    "        cv_score_iter.append(cv_ndcg_score)\n",
    "        \n",
    "    train_score_final.append(np.mean(train_score_iter))\n",
    "    cv_score_final.append(np.mean(cv_score_iter))\n",
    "\n",
    "train_score_xgb = np.mean(train_score_final)\n",
    "cv_score_xgb = np.mean(cv_score_final)\n",
    "end = time.time()\n",
    "\n",
    "print (\"\\nThe training score is: {}\".format(train_score_xgb))\n",
    "print (\"The cv score is: {}\\n\".format(cv_score_xgb))\n",
    "print('原生xgboost共耗时{}s'.format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集NDCG为0.8993966455465167\n",
      "测试集NDCG为0.804885004183881\n",
      "xgboost.Sklearn共耗时5971s\n"
     ]
    }
   ],
   "source": [
    "#  Sklearn -> XGB\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "start = time.time()\n",
    "xgb_ndcg_estimator = XGBClassifier(booster = 'gbtree',silent = False,n_estimators = 100,  # nthread = -1 用全部CPU\n",
    "                   subsample = 0.8,reg_alpha = 1.0, reg_lambda = 1.0,\n",
    "                   objective = 'multi:softprob',num_class = 12 ,colsample_bytree = 0.6,\n",
    "                   seed = 1,random_state = 100,n_jobs = 2,max_depth = 6,learning_rate = 0.3)\n",
    "xgb_kf = KFold(n_splits = 3,random_state = 100)\n",
    "\n",
    "xgb_train_score_final = []\n",
    "xgb_test_score_final = []\n",
    "for i in range(5):\n",
    "    xgb_ndcg_train_score_list = []\n",
    "    xgb_ndcg_test_score_list = []\n",
    "    for train_index,test_index in xgb_kf.split(Xtrain_list[i],Ytrain_list[i]):\n",
    "    #     print(train_index,test_index)\n",
    "        X_train,X_test = Xtrain_list[i][train_index,:],Xtrain_list[i][test_index,:]\n",
    "        Y_train,Y_test = Ytrain_list[i][train_index],Ytrain_list[i][test_index]\n",
    "\n",
    "        xgb_ndcg_estimator.fit(X_train,Y_train)\n",
    "\n",
    "        xgb_ndcg_train_proba = xgb_ndcg_estimator.predict_proba(X_train)\n",
    "        xgb_ndcg_test_proba = xgb_ndcg_estimator.predict_proba(X_test)\n",
    "\n",
    "        xgb_ndcg_train_score = ndcg_score(Y_train,xgb_ndcg_train_proba,k = 3) # 训练集ndcg\n",
    "        xgb_ndcg_test_score = ndcg_score(Y_test,xgb_ndcg_test_proba,k = 3) # 测试集ndcg\n",
    "\n",
    "        xgb_ndcg_train_score_list.append(xgb_ndcg_train_score)\n",
    "        xgb_ndcg_test_score_list.append(xgb_ndcg_test_score)\n",
    "        \n",
    "    xgb_train_score_final.append(np.mean(xgb_ndcg_train_score_list))\n",
    "    xgb_test_score_final.append(np.mean(xgb_ndcg_test_score_list))\n",
    "\n",
    "end = time.time()\n",
    "print('训练集NDCG为{}'.format(np.mean(xgb_train_score_final)))\n",
    "print('测试集NDCG为{}'.format(np.mean(xgb_test_score_final)))\n",
    "print('xgboost.Sklearn共耗时{}s'.format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集NDCG为0.8270891777031437\n",
      "测试集NDCG为0.7756198683454918\n",
      "KNN共耗时5439s\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_ndcg_estimator = KNeighborsClassifier(n_neighbors = 12)\n",
    "\n",
    "start = time.time()\n",
    "knn_kf = KFold(n_splits = 3,random_state = 100)\n",
    "\n",
    "knn_train_score_final = []\n",
    "knn_test_score_final = []\n",
    "for i in range(5):\n",
    "    knn_ndcg_train_score_list = []\n",
    "    knn_ndcg_test_score_list = []\n",
    "    for train_index,test_index in knn_kf.split(Xtrain_list[i],Ytrain_list[i]):\n",
    "    #     print(train_index,test_index)\n",
    "        X_train,X_test = Xtrain_list[i][train_index,:],Xtrain_list[i][test_index,:]\n",
    "        Y_train,Y_test = Ytrain_list[i][train_index],Ytrain_list[i][test_index]\n",
    "\n",
    "        knn_ndcg_estimator.fit(X_train,Y_train)\n",
    "\n",
    "        knn_ndcg_train_proba = knn_ndcg_estimator.predict_proba(X_train)\n",
    "        knn_ndcg_test_proba = knn_ndcg_estimator.predict_proba(X_test)\n",
    "\n",
    "        knn_ndcg_train_score = ndcg_score(Y_train,knn_ndcg_train_proba,k = 3) # 训练集ndcg\n",
    "        knn_ndcg_test_score = ndcg_score(Y_test,knn_ndcg_test_proba,k = 3) # 测试集ndcg\n",
    "\n",
    "        knn_ndcg_train_score_list.append(knn_ndcg_train_score)\n",
    "        knn_ndcg_test_score_list.append(knn_ndcg_test_score)\n",
    "        \n",
    "    knn_train_score_final.append(np.mean(knn_ndcg_train_score_list))\n",
    "    knn_test_score_final.append(np.mean(knn_ndcg_test_score_list))\n",
    "\n",
    "end = time.time()\n",
    "print('训练集NDCG为{}'.format(np.mean(knn_train_score_final)))\n",
    "print('测试集NDCG为{}'.format(np.mean(knn_test_score_final)))\n",
    "print('KNN共耗时{}s'.format(int(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
